{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as ospj\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import deque\n",
    "\n",
    "from network.model_zf import build_model\n",
    "from core.checkpoint import CheckpointIO\n",
    "from dataset.frame_dataset import FramesDataset, MotionDataset, DatasetRepeater\n",
    "import network.utils as utils\n",
    "import yaml\n",
    "import random\n",
    "from utils import Bar, Logger, AverageMeter, center\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "import pytorch_ssim\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from tps.rand_tps import RandTPS\n",
    "from network.vgg import VGG\n",
    "import imp\n",
    "from network.wing import FAN, HighPass\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/train_transformer6.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Munch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0,1, 2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-63240b439f0b>, line 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-63240b439f0b>\"\u001b[0;36m, line \u001b[0;32m200\u001b[0m\n\u001b[0;31m    train the transformer\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.args.lr = float(self.args.lr)\n",
    "        self.args.weight_decay = float(self.args.weight_decay)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.start = 10\n",
    "        self.replay_memory = 10000\n",
    "        self.replay_buffer = deque(maxlen=self.replay_memory)\n",
    "\n",
    "        self.nets = build_model(args)\n",
    "        # below setattrs are to make networks be children of Solver, e.g., for self.to(self.device)\n",
    "        for name, module in self.nets.items():\n",
    "            utils.print_network(module, name)\n",
    "            setattr(self, name, module)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.optims = Munch()\n",
    "            for net in self.nets.keys():\n",
    "                self.optims[net] = torch.optim.Adam(params=self.nets[net].parameters(), lr=float(args.lr), betas=[args.beta1, args.beta2],\n",
    "                                                   weight_decay=0)\n",
    "\n",
    "            self.ckptios = [\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets.ckpt'), **self.nets),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_optims.ckpt'), **self.optims)]\n",
    "    \n",
    "\n",
    "        self.to(self.device)\n",
    "        for name, network in self.named_children():\n",
    "            # Do not initialize the FAN parameters\n",
    "            if ('ema' not in name) and ('fan' not in name):\n",
    "                print('Initializing %s...' % name)\n",
    "                network.apply(utils.he_init)\n",
    "        \n",
    "        # landmark\n",
    "        self.fan = FAN(fname_pretrained=config.fname_fan)\n",
    "        self.fan.to(self.device)\n",
    "        self.fan.eval()\n",
    "        self.hpf = HighPass(config.w_hpf, self.device)\n",
    "        self.masking = transforms.RandomErasing(p=1.0, scale=(0.25, 0.33), ratio=(0.3, 0.33))\n",
    "        self.clip_num = config.clip_num\n",
    "        \n",
    "        # eqv\n",
    "        self.eqv_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=config.brightness, contrast=config.contrast, saturation=config.saturation, hue=config.hue),\n",
    "            transforms.ToTensor(),])\n",
    "        self.interp = nn.Upsample(size=(64, 64), mode='bilinear', align_corners=True)\n",
    "        self.tps = RandTPS(width=config.img_size, height=config.img_size, batch_size=config.batch_size, sigma=config.sigma, \n",
    "                           border_padding=True, random_mirror=True, random_scale=(0.8, 1.1))\n",
    "        self.tps.to(self.device)\n",
    "        self.tps.eval()\n",
    "        self.kl = nn.KLDivLoss().to(self.device)\n",
    "        \n",
    "        # perceptual loss\n",
    "        self.vgg = VGG()\n",
    "        MainModel = imp.load_source(\"MainModel\", args.fname_ir)\n",
    "        weight = torch.load(args.fname_vgg, map_location='cpu')\n",
    "        self.vgg.load_state_dict(weight.state_dict(), strict=False)\n",
    "        self.vgg.eval()\n",
    "        self.vgg.to(self.device)\n",
    "        \n",
    "\n",
    "    def _save_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.save(step)\n",
    "\n",
    "    def _load_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.load(step)\n",
    "\n",
    "    def _reset_grad(self):\n",
    "        for optim in self.optims.values():\n",
    "            optim.zero_grad()\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, args, epoch, nets, loader):\n",
    "        if not os.path.isdir(args.result_dir):\n",
    "            os.makedirs(args.result_dir)\n",
    "        result_target = os.path.join(args.result_dir, 'tar')\n",
    "        result_gen = os.path.join(args.result_dir,'gen')\n",
    "        if not os.path.isdir(result_target):\n",
    "            os.makedirs(result_target)\n",
    "        if not os.path.isdir(result_gen):\n",
    "            os.makedirs(result_gen)\n",
    "        \n",
    "        bar = tqdm(total=len(loader), leave=False)\n",
    "        ssim_meter, fid_meter = AverageMeter(), AverageMeter()\n",
    "        for iteration, x in enumerate(loader):\n",
    "            try:\n",
    "                test_video = torch.tensor(np.concatenate(x['video'])) # (frame, c, w, h)\n",
    "            except:\n",
    "                continue\n",
    "            num_frame = test_video.shape[0]\n",
    "            k_frame = np.random.choice(num_frame-args.K, size=2, replace=False)\n",
    "            source = test_video[[k_frame[0]]]\n",
    "            target = test_video[[k_frame[1]]]\n",
    "            real_land = self.fan.get_landmark(source.to(self.device))\n",
    "            source_out = nets.transformer(real_land, self.fan.get_landmark(target.to(self.device)))\n",
    "            source_out = self.get_clip(source_out)\n",
    "            e_out = nets.embedder(source_out)\n",
    "            source_gen = nets.generator(source.to(self.device)+F.interpolate(real_land, size=256, mode='bilinear'), e_out)\n",
    "            ssim = float(pytorch_ssim.ssim(source_gen, target.to(self.device)))\n",
    "            ssim_meter.update(ssim, iteration+1)\n",
    "            \n",
    "            # save for FID\n",
    "            gen = source_gen.squeeze().cpu().detach().numpy()\n",
    "            target = target.squeeze().cpu().detach().numpy()\n",
    "            gen = gen.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            target = target.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            gen_img = Image.fromarray((gen*255).astype('uint8'))\n",
    "            tar_img = Image.fromarray((target*255).astype('uint8'))\n",
    "            gen_img.save(result_gen + '/{}.png'.format(iteration+1))\n",
    "            tar_img.save(result_target + '/{}.png'.format(iteration+1))\n",
    "            \n",
    "            bar.set_description(\"Epoch:{:d}, SSIM: {:.8f}\".format(epoch+1, ssim_meter.avg), refresh=True)\n",
    "            bar.update()\n",
    "        bar.close()\n",
    "        val_logger.append([str(ssim_meter.avg)])\n",
    "        return\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def make_animation(self, args, nets, loaders):\n",
    "        if not os.path.isdir(args.sample_dir):\n",
    "            os.makedirs(args.sample_dir)\n",
    "        K = 100\n",
    "        random_list = np.random.choice(len(loaders.val.dataset), replace=False, size=2)\n",
    "        source_image_idx = int(random_list[0])\n",
    "        test_video_idx = int(random_list[1])\n",
    "        train_video_idx = int(np.random.choice(len(loaders.src.dataset), size=1))\n",
    "        # test animation\n",
    "        source_image = loaders.val.dataset[source_image_idx]['video'][0]\n",
    "        test_video = loaders.val.dataset[test_video_idx]['video'] # list [video](3, 256, 256)\n",
    "        train_video = loaders.src.dataset[train_video_idx]['target'] # list [K](3, 256, 256)\n",
    "        test_frame = len(test_video) if len(test_video) < K else K\n",
    "        train_frame = len(train_video)\n",
    "        predict_test, predict_train = [], []\n",
    "        for i in range(test_frame):\n",
    "            real_land = self.fan.get_landmark(source_image.to(self.device).unsqueeze(0))\n",
    "            tar_land = self.fan.get_landmark(test_video[i].to(self.device).unsqueeze(0))\n",
    "            out = nets.transformer(real_land, tar_land)\n",
    "            out = self.get_clip(out)\n",
    "            e_out = nets.embedder(out)\n",
    "            gen = nets.generator(source_image.to(self.device).unsqueeze(0)+F.interpolate(real_land, size=256, mode='bilinear'), e_out, tar_land)\n",
    "            predict_test.append(gen.cpu().detach().numpy().squeeze().swapaxes(0, 1).swapaxes(1,2))\n",
    "        \n",
    "        for i in range(train_frame):\n",
    "            real_land = self.fan.get_landmark(source_image.to(self.device).unsqueeze(0))\n",
    "            tar_land = self.fan.get_landmark(train_video[i].to(self.device).unsqueeze(0))\n",
    "            out = nets.transformer(real_land, tar_land)\n",
    "            out = self.get_clip(out)\n",
    "            e_out = nets.embedder(out)\n",
    "            gen  = nets.generator(source_image.to(self.device).unsqueeze(0)+F.interpolate(real_land, size=256, mode='bilinear'), e_out, tar_land)\n",
    "            predict_train.append(gen.cpu().detach().numpy().squeeze().swapaxes(0,1).swapaxes(1,2))\n",
    "        self.predict_test = predict_test\n",
    "        source_image = (source_image*255).numpy().swapaxes(0,1).swapaxes(1,2).astype('uint8')\n",
    "        source_img = Image.fromarray(source_image)\n",
    "        source_img.save(config.sample_dir+ '/source.png')\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_test], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in test_video], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_train], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in train_video], fps=24)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def get_clip(self, out):\n",
    "        out[out < self.clip_num] = 0.\n",
    "        return out\n",
    "\n",
    "    def train(self, loaders):\n",
    "        args = self.args\n",
    "        nets = self.nets\n",
    " \n",
    "        for name in nets:\n",
    "            nets[name] = DataParallel(nets[name])\n",
    "            nets[name] = nets[name].to(self.device)\n",
    "        optims = self.optims\n",
    "\n",
    "        # resume training if necessary\n",
    "        if args.resume_iter > 0:\n",
    "            self._load_checkpoint(args.resume_iter)\n",
    "\n",
    "        # batch\n",
    "        for epoch in range(args.resume_iter, args.epochs):\n",
    "            bar = tqdm(total=len(loaders.src)*args.K, leave=False)\n",
    "            tf_loss = AverageMeter()\n",
    "            wgan_loss, d_reg_loss = AverageMeter(), AverageMeter()\n",
    "            g_latent_loss, g_cycle_loss, vgg_loss, fm_loss = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            for i, inputs in enumerate(loaders.src):\n",
    "                x_source, y_drive = inputs['source'], inputs['target']\n",
    "                num_frame = len(y_drive)\n",
    "                for f in range(num_frame):\n",
    "                    self.replay_buffer.append((x_source, y_drive[f]))\n",
    "                    \n",
    "                    if len(self.replay_buffer) < self.start:\n",
    "                        continue\n",
    "                    minibatch = random.sample(self.replay_buffer, 1)\n",
    "                    x_source_mb, y_drive_mb = minibatch[0][0], minibatch[0][1]\n",
    "                    \n",
    "                    train the transformer\n",
    "                    x_out, landmark, tf_losses, tf_losses_latent = compute_tf_loss(nets, args, x_source_mb, y_drive_mb,\n",
    "                                                                         transform=self.eqv_transform, tps=self.tps, interp=self.interp, \n",
    "                                                                         kl=self.kl, fan=self.fan, mask=self.masking,\n",
    "                                                                         device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    tf_losses.backward()\n",
    "                    optims.transformer.step()\n",
    "                    x_out = self.get_clip(x_out).detach()\n",
    "                    \n",
    "                    # train the discriminator\n",
    "                    feat, d_loss, d_losses_latent = compute_d_loss(nets, args, x_source_mb, y_drive_mb, x_out, landmark[0], landmark[1], device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    d_loss.backward()\n",
    "                    optims.discriminator.step()\n",
    "                    \n",
    "                    # train the generator\n",
    "                    g_loss, g_losses_latent = compute_g_loss(nets, args, x_source_mb, y_drive_mb, x_out, landmark[0], landmark[1], vgg=self.vgg, \n",
    "                                                             fan=self.fan, device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    g_loss.backward()\n",
    "                    optims.generator.step()\n",
    "                    optims.embedder.step()\n",
    "                    \n",
    "                    wgan_loss.update(float(d_losses_latent.wgangp), x_source.size(0))\n",
    "                    d_reg_loss.update(float(d_losses_latent.reg), x_source.size(0))\n",
    "                    g_latent_loss.update(float(g_losses_latent.adv), x_source.size(0))\n",
    "                    g_cycle_loss.update(float(g_losses_latent.cyc), x_source.size(0))\n",
    "                    vgg_loss.update(float(g_losses_latent.vgg), x_source.size(0))\n",
    "                    fm_loss.update(float(g_losses_latent.fm), x_source.size(0))\n",
    "                    tf_loss.update(float(tf_losses_latent.tf), x_source.size(0))\n",
    "\n",
    "                    bar.set_description(\"Ep:{:d}, D: {:.6f}, R1: {:.2f}, G: {:.6f}, Cyc: {:.6f}, Vgg: {:.6f}, FM: {:.6f}, TF: {:.6f}\".format(\n",
    "                                        epoch+1, wgan_loss.avg, d_reg_loss.avg, \n",
    "                                        g_latent_loss.avg, g_cycle_loss.avg, vgg_loss.avg, fm_loss.avg,\n",
    "                                        tf_loss.avg), refresh=True)\n",
    "                    bar.update()\n",
    "            bar.close()\n",
    "\n",
    "                # save model checkpoints\n",
    "            logger.append([str(wgan_loss.avg)[:8], str(d_reg_loss.avg)[:8], \n",
    "                           str(g_latent_loss.avg)[:8], str(g_cycle_loss.avg)[:8], str(vgg_loss.avg)[:8], str(fm_loss.avg)[:8],\n",
    "                           str(tf_loss.avg)[:8]])\n",
    "            if (epoch+1) % config.save_every == 0:\n",
    "                self._save_checkpoint(step=epoch+1)\n",
    "\n",
    "            # compute SSIM and FID in test_set\n",
    "            if (epoch+1) % config.eval_every == 0:\n",
    "                self.evaluate(args, epoch, nets, loaders.val)\n",
    "                \n",
    "            self.make_animation(args, nets, loaders)\n",
    "        \n",
    "        self.evaluate(args, epoch, nets, loaders.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_loss(nets, args, x_real, y_org, transform, tps, interp, kl, fan, mask, device='cuda'):\n",
    "    # TF_loss\n",
    "    l1_loss = nn.L1Loss()\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_landmark = fan.get_landmark(x_real)\n",
    "    y_landmark = fan.get_landmark(y_org)\n",
    "    y_land_masked = []\n",
    "    for i in range(y_landmark.size(0)):\n",
    "        y_land_masked.append(mask(y_landmark[i].clone()).cpu().numpy())\n",
    "    y_land_masked = torch.from_numpy(np.array(y_land_masked))\n",
    "    x_out = nets.transformer(x_landmark, y_land_masked)\n",
    "    loss_tf = l1_loss(x_out, y_landmark)\n",
    "    # Equivariance loss\n",
    "    # real --> transform(color / tps) --> gen\n",
    "#     softmax = nn.Softmax(dim=1)\n",
    "#     images_cj = x_real\n",
    "#     for b in range(images_cj.shape[0]):\n",
    "#         images_cj[b] = transform(images_cj[b].cpu())\n",
    "#     tps.reset_control_points()\n",
    "#     images_tps = tps(images_cj.to(device))\n",
    "#     images_tps_landmark = fan.get_landmark(images_tps)\n",
    "#     pred_tps =  nets.transformer(images_tps_landmark, y_landmark)\n",
    "#     # real --> gen --> transform(tps)\n",
    "#     pred_d = x_out\n",
    "#     pred_d = pred_d.detach()\n",
    "#     pred_d.requires_grad = False\n",
    "#     pred_tps_org = F.interpolate(torch.sum(tps(pred_d.repeat(1, 3, 1, 1)), 1, keepdim=True)/3., size=64)\n",
    "#     # KL (first, second) / Center mse (first, second)\n",
    "#     loss_eqv = kl(F.log_softmax(pred_tps, dim=1), F.softmax(pred_tps_org))\n",
    "    loss = loss_tf * args.lambda_tf\n",
    "    return x_out, (x_landmark, y_landmark), loss, Munch(tf=loss_tf.item())\n",
    "\n",
    "def compute_d_loss(nets, args, x_real, y_org, x_out, x_landmark,  y_landmark, device='cuda'):\n",
    "    # with real images\n",
    "    x_real, y_org, x_out = x_real.to(device), y_org.to(device), x_out.to(device)\n",
    "    x_real.requires_grad = True\n",
    "    real_out, r_feat = nets.discriminator(x_real)\n",
    "    loss_real = adv_loss(real_out, 1)\n",
    "    # R1-reg\n",
    "    loss_reg = r1_reg(real_out, x_real)\n",
    "     # with fake images\n",
    "    with torch.no_grad():\n",
    "        e = nets.embedder(x_out)\n",
    "        x_fake = nets.generator(x_real+F.interpolate(x_landmark, size=256, mode='bilinear'), e, y_landmark)\n",
    "    fake_out, f_feat = nets.discriminator(x_fake)\n",
    "    loss_fake = adv_loss(fake_out, 0)\n",
    "    loss = loss_real + loss_fake + args.lambda_reg * loss_reg\n",
    "    return (r_feat, f_feat),loss, Munch(wgangp=loss_real.item()+loss_fake.item(), reg=loss_reg.item())\n",
    "\n",
    "def compute_g_loss(nets, args, x_real, y_org, x_out, x_landmark, y_landmark, vgg, fan, device='cuda'):\n",
    "    # adversarial loss\n",
    "    x_real, y_org, x_out= x_real.to(device), y_org.to(device), x_out.to(device)\n",
    "    x_real_ld = x_real + F.interpolate(x_landmark, size=256, mode='bilinear')\n",
    "    e = nets.embedder(x_out)\n",
    "    x_fake = nets.generator(x_real_ld, e, y_landmark)\n",
    "    out, _ = nets.discriminator(x_fake)\n",
    "    # adv loss\n",
    "    loss_adv = adv_loss(out, 1)\n",
    "    \n",
    "    # feature-matching loss\n",
    "    l1_loss = nn.L1Loss()\n",
    "    _, target_feat = nets.discriminator(y_org)\n",
    "    loss_fm = l1_loss(e, target_feat.detach())\n",
    "    \n",
    "    # cycle-consistency loss\n",
    "    x_fake_landmark = fan.get_landmark(x_fake)\n",
    "    x_real_landmark = fan.get_landmark(x_real)\n",
    "    x_fake_out = nets.transformer(x_fake_landmark, x_real_landmark)\n",
    "    e_cyc = nets.embedder(x_fake_out)\n",
    "    x_rec = nets.generator(x_fake+F.interpolate(x_fake_landmark, size=256, mode='bilinear'), e_cyc, x_landmark)\n",
    "    loss_cyc = torch.mean(torch.abs(x_rec - x_real))\n",
    "    \n",
    "    # perceptual loss\n",
    "    with torch.no_grad():\n",
    "        vgg_x = vgg(y_org)\n",
    "    with torch.autograd.enable_grad():\n",
    "        vgg_xhat = vgg(x_fake)\n",
    "        \n",
    "    loss_vgg = 0\n",
    "    for x_feat, xhat_feat in zip(vgg_x, vgg_xhat):\n",
    "        loss_vgg += l1_loss(x_feat, xhat_feat)\n",
    "\n",
    "    loss = loss_adv + args.lambda_cyc * loss_cyc + args.lambda_vgg * loss_vgg + args.lambda_fm * loss_fm\n",
    "    return loss, Munch(adv=loss_adv.item(), cyc=loss_cyc.item(), vgg=loss_vgg.item(), fm=loss_fm.item())\n",
    "\n",
    "def gradient_penalty(nets, real, fake, reg_lambda=10, device='cuda'):\n",
    "    from torch.autograd import grad\n",
    "    batch_size = real.shape[0]\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    merged = (epsilon * real) + ((1 - epsilon) * fake)\n",
    "    # forward\n",
    "    op = nets.discriminator(merged)\n",
    "    \n",
    "    # merted gradient\n",
    "    gradient = grad(outputs=op, inputs=merged, create_graph=True, grad_outputs=torch.ones_like(op), \n",
    "                    retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    # calc penalty\n",
    "    penalty = reg_lambda * ((gradient.norm(p=2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty\n",
    "    \n",
    "def moving_average(model, model_test, beta=0.999):\n",
    "    for param, param_test in zip(model.parameters(), model_test.parameters()):\n",
    "        param_test.data = torch.lerp(param.data, param_test.data, beta)\n",
    "\n",
    "def adv_loss(logits, target):\n",
    "    assert target in [1, 0]\n",
    "    targets = torch.full_like(logits, fill_value=target)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    return loss\n",
    "\n",
    "def r1_reg(d_out, x_in):\n",
    "    # zero-centered gradient penalty for real images\n",
    "    batch_size = x_in.size(0)\n",
    "    grad_dout = torch.autograd.grad(\n",
    "        outputs=d_out.sum(), inputs=x_in,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    assert(grad_dout2.size() == x_in.size())\n",
    "    reg = 0.5 * grad_dout2.view(batch_size, -1).sum(1).mean(0)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MotionDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=True, random_seed=config.seed)\n",
    "test_dataset = FramesDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=False, random_seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRepeater(train_dataset, config.num_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                              num_workers=config.num_workers, pin_memory=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = Munch(src=train_loader, val=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'), resume=True)\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'))\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'))\n",
    "    logger.set_names(['WGAN-GP Loss', 'R1reg Loss', 'G-latent-adv Loss', 'G-cyclc Loss', 'Perceptual Loss', 'Feature-matching Loss', 'TF L1 Loss'])\n",
    "    val_logger.set_names(['SSIM measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver.train(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
