{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as ospj\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from network.model_g import build_model\n",
    "from core.checkpoint import CheckpointIO\n",
    "# from dataset.data_loader import InputFetcher\n",
    "from dataset.frame_dataset import FramesDataset, DatasetRepeater\n",
    "import network.utils as utils\n",
    "import yaml\n",
    "import random\n",
    "from utils import Bar, Logger, AverageMeter, center\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "import pytorch_ssim\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from tps.rand_tps import RandTPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/train_transformer3.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Munch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0, 1, 2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.args.lr = float(self.args.lr)\n",
    "        self.args.weight_decay = float(self.args.weight_decay)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.start = 0\n",
    "\n",
    "        self.nets, self.nets_ema = build_model(args)\n",
    "        # below setattrs are to make networks be children of Solver, e.g., for self.to(self.device)\n",
    "        for name, module in self.nets.items():\n",
    "            utils.print_network(module, name)\n",
    "            setattr(self, name, module)\n",
    "        for name, module in self.nets_ema.items():\n",
    "            setattr(self, name + '_ema', module)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.optims = Munch()\n",
    "            for net in self.nets.keys():\n",
    "                self.optims[net] = torch.optim.Adam(params=self.nets[net].parameters(), lr=float(args.lr), betas=[args.beta1, args.beta2])\n",
    "\n",
    "            self.ckptios = [\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets.ckpt'), **self.nets),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_optims.ckpt'), **self.optims)]\n",
    "        else:\n",
    "            self.ckptios = [CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema)]\n",
    "    \n",
    "\n",
    "        self.to(self.device)\n",
    "        for name, network in self.named_children():\n",
    "            # Do not initialize the FAN parameters\n",
    "            if ('ema' not in name) and ('fan' not in name):\n",
    "                print('Initializing %s...' % name)\n",
    "                network.apply(utils.he_init)\n",
    "        \n",
    "        # eqv\n",
    "        self.eqv_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=config.brightness, contrast=config.contrast, saturation=config.saturation, hue=config.hue),\n",
    "            transforms.ToTensor(),])\n",
    "        self.interp = nn.Upsample(size=(config.img_size, config.img_size), mode='bilinear', align_corners=True)\n",
    "        self.tps = RandTPS(width=config.img_size, height=config.img_size, batch_size=config.batch_size, sigma=config.sigma, \n",
    "                           border_padding=True, random_mirror=True, random_scale=(0.8, 1.1))\n",
    "        self.kl = nn.KLDivLoss().to(self.device)\n",
    "        \n",
    "\n",
    "    def _save_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.save(step)\n",
    "\n",
    "    def _load_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.load(step)\n",
    "\n",
    "    def _reset_grad(self):\n",
    "        for optim in self.optims.values():\n",
    "            optim.zero_grad()\n",
    "\n",
    "    def train(self, loaders):\n",
    "        args = self.args\n",
    "        nets = self.nets\n",
    "        nets_ema = self.nets_ema\n",
    "        \n",
    "        for name in nets:\n",
    "            nets[name] = DataParallel(nets[name])\n",
    "            nets[name] = nets[name].to(self.device)\n",
    "        optims = self.optims\n",
    "\n",
    "        # resume training if necessary\n",
    "        if args.resume_iter > 0:\n",
    "            self._load_checkpoint(args.resume_iter)\n",
    "\n",
    "\n",
    "        # batch\n",
    "#         for i in range(args.resume_iter, args.total_iters):\n",
    "        for epoch in range(args.resume_iter, args.epochs):\n",
    "            bar = tqdm(total=len(loaders.src), leave=False)\n",
    "            wgan_loss, d_reg_loss = AverageMeter(), AverageMeter()\n",
    "            g_latent_loss, g_cycle_loss, eqv_loss, center_loss = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            for i, inputs in enumerate(loaders.src):\n",
    "                x_source, y_drive = inputs['source'], inputs['target']\n",
    "                # train the discriminator\n",
    "                d_loss, d_losses_latent = compute_d_loss(nets, args, x_source, y_drive, device=self.device)\n",
    "                self._reset_grad()\n",
    "                d_loss.backward()\n",
    "                optims.discriminator.step()\n",
    "\n",
    "                # train the generator\n",
    "                g_loss, g_losses_latent = compute_g_loss(nets, args, x_source, y_drive, \n",
    "                                                         transform=self.eqv_transform, tps=self.tps, interp=self.interp, kl=self.kl, \n",
    "                                                         device=self.device)\n",
    "                self._reset_grad()\n",
    "                g_loss.backward()\n",
    "                optims.generator.step()\n",
    "\n",
    "                moving_average(nets.generator, nets_ema.generator, beta=0.999)\n",
    "\n",
    "                wgan_loss.update(float(d_losses_latent.wgangp), x_source.size(0))\n",
    "                d_reg_loss.update(float(d_losses_latent.reg), x_source.size(0))\n",
    "                g_latent_loss.update(float(g_losses_latent.adv), x_source.size(0))\n",
    "                g_cycle_loss.update(float(g_losses_latent.cyc), x_source.size(0))\n",
    "                eqv_loss.update(float(g_losses_latent.eqv), x_source.size(0))\n",
    "                center_loss.update(float(g_losses_latent.center), x_source.size(0))\n",
    "\n",
    "                \n",
    "                bar.set_description(\"Ep:{:d}, WGP: {:.6f}, R1: {:.2f}, G: {:.6f}, Cyc: {:.6f}, Eqv: {:.6f}, Ct: {:.6f}\".format(\n",
    "                                    epoch+1, wgan_loss.avg, d_reg_loss.avg, \n",
    "                                    g_latent_loss.avg, g_cycle_loss.avg, eqv_loss.avg, center_loss.avg), refresh=True)\n",
    "                bar.update()\n",
    "            bar.close()\n",
    "\n",
    "                # save model checkpoints\n",
    "            logger.append([str(wgan_loss.avg)[:8], str(d_reg_loss.avg)[:8], \n",
    "                           str(g_latent_loss.avg)[:8], str(g_cycle_loss.avg)[:8], str(eqv_loss.avg)[:8], str(center_loss.avg)[:8]])\n",
    "            if (epoch+1) % config.save_every == 0:\n",
    "                self._save_checkpoint(step=epoch+1)\n",
    "\n",
    "            # compute SSIM and FID in test_set\n",
    "            if (epoch+1) % config.eval_every == 0:\n",
    "                self.evaluate(epoch, nets, loaders.val)\n",
    "        \n",
    "        self.evaluate(epoch, nets, loaders.val)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, epoch, nets, loader):\n",
    "        if not os.path.isdir(config.result_dir):\n",
    "            os.makedirs(config.result_dir)\n",
    "        result_target = os.path.join(config.result_dir, 'tar')\n",
    "        result_gen = os.path.join(config.result_dir,'gen')\n",
    "        if not os.path.isdir(result_target):\n",
    "            os.makedirs(result_target)\n",
    "        if not os.path.isdir(result_gen):\n",
    "            os.makedirs(result_gen)\n",
    "        \n",
    "        bar = tqdm(total=len(loader), leave=False)\n",
    "        ssim_meter, fid_meter = AverageMeter(), AverageMeter()\n",
    "        for iteration, x in enumerate(loader):\n",
    "            test_video = torch.tensor(np.concatenate(x['video'])) # (frame, c, w, h)\n",
    "            num_frame = test_video.shape[0]\n",
    "            k_frame = np.random.choice(num_frame-config.K, size=2, replace=False)\n",
    "            source = test_video[[k_frame[0]]]\n",
    "            target = test_video[[k_frame[1]]]\n",
    "            source_gen, _  = nets.generator(source.to(self.device), target.to(self.device))\n",
    "            \n",
    "            ssim = float(pytorch_ssim.ssim(source_gen, target.to(self.device)))\n",
    "            ssim_meter.update(ssim, iteration+1)\n",
    "            \n",
    "            # save for FID\n",
    "            gen = source_gen.squeeze().cpu().detach().numpy()\n",
    "            target = target.squeeze().cpu().detach().numpy()\n",
    "            gen = gen.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            target = target.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            gen_img = Image.fromarray((gen*255).astype('uint8'))\n",
    "            tar_img = Image.fromarray((target*255).astype('uint8'))\n",
    "            gen_img.save(result_gen + '/{}.png'.format(iteration+1))\n",
    "            tar_img.save(result_target + '/{}.png'.format(iteration+1))\n",
    "            \n",
    "            bar.set_description(\"Epoch:{:d}, SSIM: {:.8f}\".format(epoch+1, ssim_meter.avg), refresh=True)\n",
    "            bar.update()\n",
    "        bar.close()\n",
    "        val_logger.append([str(ssim_meter.avg)])\n",
    "        return\n",
    "    \n",
    "    def make_animation(self, net, loader):\n",
    "        if not os.path.isdir(config.result_dir):\n",
    "            os.makedirs(config.result_dir)\n",
    "        pass\n",
    "            \n",
    "def compute_d_loss(nets, args, x_real, y_org, device='cuda'):\n",
    "#     assert (z_trg is None) != (x_ref is None)\n",
    "    # with real images\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_real.requires_grad = True\n",
    "    y_org.requires_grad = True\n",
    "    real_out = nets.discriminator(y_org)\n",
    "     # with fake images\n",
    "    with torch.no_grad():\n",
    "        x_fake, _ = nets.generator(x_real, y_org)\n",
    "    fake_out = nets.discriminator(x_fake)\n",
    "    loss_reg = r1_reg(real_out, y_org)\n",
    "    \n",
    "    loss = (torch.mean(fake_out) - torch.mean(real_out) + (args.drift * torch.mean(real_out ** 2)))\n",
    "    x_fake.requires_grad = True\n",
    "    gp = gradient_penalty(nets, y_org, x_fake, args.lambda_gp, device=device)\n",
    "    loss += gp\n",
    "\n",
    "    loss = loss + args.lambda_reg * loss_reg\n",
    "    return loss, Munch(wgangp=loss.item(), reg=loss_reg.item())\n",
    "\n",
    "\n",
    "def compute_g_loss(nets, args, x_real, y_org, transform, tps, interp, kl, device='cuda'):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    # adversarial loss\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_fake, x_att = nets.generator(x_real, y_org)\n",
    "    out = nets.discriminator(x_fake)\n",
    "    loss_adv = adv_loss(out, 1)\n",
    "    \n",
    "    # Equivariance loss\n",
    "    # real --> transform(color / tps) --> gen\n",
    "    images_cj = torch.from_numpy(x_real.cpu().detach().numpy())\n",
    "    for b in range(images_cj.shape[0]):\n",
    "        images_cj[b] = torch.from_numpy(transform(images_cj[b]).numpy()*255.0)\n",
    "    tps.reset_control_points()\n",
    "    images_tps = tps(images_cj)\n",
    "    pred_tps, _ =  nets.generator((images_tps/255.0).to(device), y_org)\n",
    "    pred_tps = interp(pred_tps)\n",
    "    # real --> gen --> transform(tps)\n",
    "    pred_d = x_fake.cpu().detach()\n",
    "    pred_d.requires_grad = False\n",
    "    pred_tps_org = tps(pred_d, padding_mode='zeros')\n",
    "    # Center: first center - second center\n",
    "    centers_tps = center.batch_get_centers(softmax(pred_tps)[:, 1:, :, :])\n",
    "    pred_tps_gen = tps(x_fake.cpu(), padding_mode='zeros')\n",
    "    centers_tps_gen = center.batch_get_centers(softmax(pred_tps_gen.to(device))[:, 1:, :, :])\n",
    "    # KL (first, second) / Center mse (first, second)\n",
    "    loss_eqv = kl(F.log_softmax(pred_tps, dim=1), F.softmax(pred_tps_org.to(device)))\n",
    "    loss_center = F.mse_loss(centers_tps, centers_tps_gen)\n",
    "\n",
    "    # cycle-consistency loss\n",
    "    x_rec, x_tf = nets.generator(x_fake, x_real)\n",
    "    loss_cyc = torch.mean(torch.abs(x_rec - x_real)) + torch.mean(torch.abs(x_att - x_tf))\n",
    "\n",
    "    loss = loss_adv + args.lambda_cyc * loss_cyc + args.lambda_eqv * loss_eqv + args.lambda_eqv * loss_center\n",
    "    return loss, Munch(adv=loss_adv.item(), cyc=loss_cyc.item(), eqv=loss_eqv.item(), center=loss_center.item())\n",
    "\n",
    "def compute_tf_loss(nets, args, x_att, t_att, device='cuda'):\n",
    "    pass\n",
    "\n",
    "def gradient_penalty(nets, real, fake, reg_lambda=10, device='cuda'):\n",
    "    from torch.autograd import grad\n",
    "    batch_size = real.shape[0]\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    merged = (epsilon * real) + ((1 - epsilon) * fake)\n",
    "    # forward\n",
    "    op = nets.discriminator(merged)\n",
    "    \n",
    "    # merted gradient\n",
    "    gradient = grad(outputs=op, inputs=merged, create_graph=True, grad_outputs=torch.ones_like(op), \n",
    "                    retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    # calc penalty\n",
    "    penalty = reg_lambda * ((gradient.norm(p=2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty\n",
    "    \n",
    "\n",
    "def moving_average(model, model_test, beta=0.999):\n",
    "    for param, param_test in zip(model.parameters(), model_test.parameters()):\n",
    "        param_test.data = torch.lerp(param.data, param_test.data, beta)\n",
    "\n",
    "\n",
    "def adv_loss(logits, target):\n",
    "    assert target in [1, 0]\n",
    "    targets = torch.full_like(logits, fill_value=target)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def r1_reg(d_out, x_in):\n",
    "    # zero-centered gradient penalty for real images\n",
    "    batch_size = x_in.size(0)\n",
    "    grad_dout = torch.autograd.grad(\n",
    "        outputs=d_out.sum(), inputs=x_in,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    assert(grad_dout2.size() == x_in.size())\n",
    "    reg = 0.5 * grad_dout2.view(batch_size, -1).sum(1).mean(0)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n",
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FramesDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=True, random_seed=config.seed)\n",
    "test_dataset = FramesDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=False, random_seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRepeater(train_dataset, config.num_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                              num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = Munch(src=train_loader, val=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of generator: 59922063\n",
      "Number of parameters of discriminator: 20851777\n",
      "Initializing generator...\n",
      "Initializing discriminator...\n"
     ]
    }
   ],
   "source": [
    "solver = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'), resume=True)\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'))\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'))\n",
    "    logger.set_names(['WGAN-GP Loss', 'R1reg Loss', 'G-latent-adv Loss', 'G-cyclc Loss', 'Equivariance Loss', 'Eqv-center Loss'])\n",
    "    val_logger.set_names(['SSIM measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep:1, WGP: 642735.463819, R1: 605093.57, G: 214663.659345, Cyc: 0.603163, Eqv: 0.031992, Ct: 0.001172:  16%|█▌        | 62/384 [04:50<22:51,  4.26s/it]  "
     ]
    }
   ],
   "source": [
    "solver.train(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
