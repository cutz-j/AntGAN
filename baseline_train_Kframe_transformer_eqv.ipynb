{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as ospj\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from network.model_g import build_model\n",
    "from core.checkpoint import CheckpointIO\n",
    "# from dataset.data_loader import InputFetcher\n",
    "from dataset.frame_dataset import FramesDataset, MotionDataset, DatasetRepeater\n",
    "import network.utils as utils\n",
    "import yaml\n",
    "import random\n",
    "from utils import Bar, Logger, AverageMeter, center\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "import pytorch_ssim\n",
    "from torchvision import transforms\n",
    "from tps.rand_tps import RandTPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio\n",
    "from skimage import img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/train_transformer3.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Munch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.args.lr = float(self.args.lr)\n",
    "        self.args.weight_decay = float(self.args.weight_decay)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.start = 0\n",
    "\n",
    "        self.nets, self.nets_ema = build_model(args)\n",
    "        # below setattrs are to make networks be children of Solver, e.g., for self.to(self.device)\n",
    "        for name, module in self.nets.items():\n",
    "            utils.print_network(module, name)\n",
    "            setattr(self, name, module)\n",
    "        for name, module in self.nets_ema.items():\n",
    "            setattr(self, name + '_ema', module)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.optims = Munch()\n",
    "            for net in self.nets.keys():\n",
    "                self.optims[net] = torch.optim.Adam(params=self.nets[net].parameters(), lr=float(args.lr), betas=[args.beta1, args.beta2])\n",
    "\n",
    "            self.ckptios = [\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets.ckpt'), **self.nets),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_optims.ckpt'), **self.optims)]\n",
    "        else:\n",
    "            self.ckptios = [CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema)]\n",
    "    \n",
    "\n",
    "        self.to(self.device)\n",
    "        for name, network in self.named_children():\n",
    "            # Do not initialize the FAN parameters\n",
    "            if ('ema' not in name) and ('fan' not in name):\n",
    "                print('Initializing %s...' % name)\n",
    "                network.apply(utils.he_init)\n",
    "        \n",
    "        # eqv\n",
    "        self.eqv_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=config.brightness, contrast=config.contrast, saturation=config.saturation, hue=config.hue),\n",
    "            transforms.ToTensor(),])\n",
    "        self.interp = nn.Upsample(size=(config.img_size, config.img_size), mode='bilinear', align_corners=True)\n",
    "        self.tps = RandTPS(width=config.img_size, height=config.img_size, batch_size=config.batch_size, sigma=config.sigma, \n",
    "                           border_padding=True, random_mirror=True, random_scale=(0.8, 1.1))\n",
    "        self.kl = nn.KLDivLoss().to(self.device)\n",
    "        \n",
    "\n",
    "    def _save_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.save(step)\n",
    "\n",
    "    def _load_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.load(step)\n",
    "\n",
    "    def _reset_grad(self):\n",
    "        for optim in self.optims.values():\n",
    "            optim.zero_grad()\n",
    "\n",
    "    def train(self, loaders):\n",
    "        args = self.args\n",
    "        nets = self.nets\n",
    "        nets_ema = self.nets_ema\n",
    "        \n",
    "        for name in nets:\n",
    "            nets[name] = DataParallel(nets[name])\n",
    "            nets[name] = nets[name].to(self.device)\n",
    "        optims = self.optims\n",
    "\n",
    "        # resume training if necessary\n",
    "        if args.resume_iter > 0:\n",
    "            self._load_checkpoint(args.resume_iter)\n",
    "\n",
    "\n",
    "        # batch\n",
    "#         for i in range(args.resume_iter, args.total_iters):\n",
    "        for epoch in range(args.resume_iter, args.epochs):\n",
    "            bar = tqdm(total=len(loaders.src)*args.K, leave=False)\n",
    "            wgan_loss, d_reg_loss = AverageMeter(), AverageMeter()\n",
    "            g_latent_loss, g_cycle_loss, eqv_loss, center_loss = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            for i, inputs in enumerate(loaders.src):\n",
    "                x_source, y_drive = inputs['source'], inputs['target']\n",
    "                num_frame = len(y_drive)\n",
    "                for f in range(num_frame):\n",
    "                \n",
    "                    # train the discriminator\n",
    "                    d_loss, d_losses_latent = compute_d_loss(nets, args, x_source, y_drive[f], device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    d_loss.backward()\n",
    "                    optims.discriminator.step()\n",
    "\n",
    "                    # train the generator\n",
    "                    g_loss, g_losses_latent = compute_g_loss(nets, args, x_source, y_drive[f], \n",
    "                                                             transform=self.eqv_transform, tps=self.tps, interp=self.interp, kl=self.kl, \n",
    "                                                             device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    g_loss.backward()\n",
    "                    optims.generator.step()\n",
    "\n",
    "                    moving_average(nets.generator, nets_ema.generator, beta=0.999)\n",
    "\n",
    "                    wgan_loss.update(float(d_losses_latent.wgangp), x_source.size(0))\n",
    "                    d_reg_loss.update(float(d_losses_latent.reg), x_source.size(0))\n",
    "                    g_latent_loss.update(float(g_losses_latent.adv), x_source.size(0))\n",
    "                    g_cycle_loss.update(float(g_losses_latent.cyc), x_source.size(0))\n",
    "                    eqv_loss.update(float(g_losses_latent.eqv), x_source.size(0))\n",
    "                    center_loss.update(float(g_losses_latent.center), x_source.size(0))\n",
    "\n",
    "\n",
    "                    bar.set_description(\"Ep:{:d}, WGP: {:.6f}, R1: {:.2f}, G: {:.6f}, Cyc: {:.6f}, Eqv: {:.6f}, Ct: {:.6f}\".format(\n",
    "                                        epoch+1, wgan_loss.avg, d_reg_loss.avg, \n",
    "                                        g_latent_loss.avg, g_cycle_loss.avg, eqv_loss.avg, center_loss.avg), refresh=True)\n",
    "                    bar.update()\n",
    "            bar.close()\n",
    "\n",
    "                # save model checkpoints\n",
    "            logger.append([str(wgan_loss.avg)[:8], str(d_reg_loss.avg)[:8], \n",
    "                           str(g_latent_loss.avg)[:8], str(g_cycle_loss.avg)[:8], str(eqv_loss.avg)[:8], str(center_loss.avg)[:8]])\n",
    "            if (epoch+1) % config.save_every == 0:\n",
    "                self._save_checkpoint(step=epoch+1)\n",
    "\n",
    "            # compute SSIM and FID in test_set\n",
    "            if (epoch+1) % config.eval_every == 0:\n",
    "                self.evaluate(epoch, nets, loaders.val)\n",
    "                \n",
    "            self.make_animation(nets.generator, loaders)\n",
    "        \n",
    "        self.evaluate(epoch, nets, loaders.val)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, epoch, nets, loader):\n",
    "        if not os.path.isdir(config.result_dir):\n",
    "            os.makedirs(config.result_dir)\n",
    "        result_target = os.path.join(config.result_dir, 'tar')\n",
    "        result_gen = os.path.join(config.result_dir,'gen')\n",
    "        if not os.path.isdir(result_target):\n",
    "            os.makedirs(result_target)\n",
    "        if not os.path.isdir(result_gen):\n",
    "            os.makedirs(result_gen)\n",
    "        \n",
    "        bar = tqdm(total=len(loader), leave=False)\n",
    "        ssim_meter, fid_meter = AverageMeter(), AverageMeter()\n",
    "        for iteration, x in enumerate(loader):\n",
    "            test_video = torch.tensor(np.concatenate(x['video'])) # (frame, c, w, h)\n",
    "            num_frame = test_video.shape[0]\n",
    "            k_frame = np.random.choice(num_frame-config.K, size=2, replace=False)\n",
    "            source = test_video[[k_frame[0]]]\n",
    "            target = test_video[[k_frame[1]]]\n",
    "            source_gen, _  = nets.generator(source.to(self.device), target.to(self.device))\n",
    "            \n",
    "            ssim = float(pytorch_ssim.ssim(source_gen, target.to(self.device)))\n",
    "            ssim_meter.update(ssim, iteration+1)\n",
    "            \n",
    "            # save for FID\n",
    "            gen = source_gen.squeeze().cpu().detach().numpy()\n",
    "            target = target.squeeze().cpu().detach().numpy()\n",
    "            gen = gen.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            target = target.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            gen_img = Image.fromarray((gen*255).astype('uint8'))\n",
    "            tar_img = Image.fromarray((target*255).astype('uint8'))\n",
    "            gen_img.save(result_gen + '/{}.png'.format(iteration+1))\n",
    "            tar_img.save(result_target + '/{}.png'.format(iteration+1))\n",
    "            \n",
    "            bar.set_description(\"Epoch:{:d}, SSIM: {:.8f}\".format(epoch+1, ssim_meter.avg), refresh=True)\n",
    "            bar.update()\n",
    "        bar.close()\n",
    "        val_logger.append([str(ssim_meter.avg)])\n",
    "        return\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def make_animation(self, generator, loaders):\n",
    "        if not os.path.isdir(config.sample_dir):\n",
    "            os.makedirs(config.sample_dir)\n",
    "        K = 100\n",
    "        random_list = np.random.choice(len(loaders.val.dataset), replace=False, size=2)\n",
    "        source_image_idx = int(random_list[0])\n",
    "        test_video_idx = int(random_list[1])\n",
    "        train_video_idx = int(np.random.choice(len(loaders.src.dataset), size=1))\n",
    "        # test animation\n",
    "        source_image = loaders.val.dataset[source_image_idx]['video'][0]\n",
    "        test_video = loaders.val.dataset[test_video_idx]['video'] # list [video](3, 256, 256)\n",
    "        train_video = loaders.src.dataset[train_video_idx]['target'] # list [K](3, 256, 256)\n",
    "        test_frame = len(test_video) if len(test_video) < K else K\n",
    "        train_frame = len(train_video)\n",
    "        predict_test, predict_train = [], []\n",
    "        for i in range(test_frame):\n",
    "            gen, _ = generator(source_image.to(self.device).unsqueeze(0), test_video[i].to(self.device).unsqueeze(0))\n",
    "            predict_test.append(gen.cpu().detach().numpy().squeeze().swapaxes(0, 1).swapaxes(1,2))\n",
    "        \n",
    "        for i in range(train_frame):\n",
    "            gen, _ = generator(source_image.to(self.device).unsqueeze(0), train_video[i].to(self.device).unsqueeze(0))\n",
    "            predict_train.append(gen.cpu().detach().numpy().squeeze().swapaxes(0,1).swapaxes(1,2))\n",
    "        self.predict_test = predict_test\n",
    "        source_image = (source_image*255).numpy().swapaxes(0,1).swapaxes(1,2).astype('uint8')\n",
    "        source_img = Image.fromarray(source_image)\n",
    "        source_img.save(config.sample_dir+ '/source.png')\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_test], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in test_video], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_train], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in train_video], fps=24)\n",
    "        \n",
    "def compute_d_loss(nets, args, x_real, y_org, device='cuda'):\n",
    "#     assert (z_trg is None) != (x_ref is None)\n",
    "    # with real images\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_real.requires_grad = True\n",
    "    real_out = nets.discriminator(x_real)\n",
    "    # R1-reg\n",
    "    loss_reg = r1_reg(real_out, x_real)\n",
    "     # with fake images\n",
    "    with torch.no_grad():\n",
    "        x_fake, _ = nets.generator(x_real, y_org)\n",
    "    fake_out = nets.discriminator(x_fake)\n",
    "    # WGAN-GP\n",
    "    loss = (torch.mean(fake_out) - torch.mean(real_out) + (args.drift * torch.mean(real_out ** 2)))\n",
    "    x_fake.requires_grad = True\n",
    "    gp = gradient_penalty(nets, x_real, x_fake, args.lambda_gp, device=device)\n",
    "    loss += gp\n",
    "    loss = loss + args.lambda_reg * loss_reg\n",
    "    return loss, Munch(wgangp=loss.item(), reg=loss_reg.item())\n",
    "\n",
    "\n",
    "def compute_g_loss(nets, args, x_real, y_org, transform, tps, interp, kl, device='cuda'):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    # adversarial loss: WGAN-GP\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_fake, x_att = nets.generator(x_real, y_org)\n",
    "    out = nets.discriminator(x_fake)\n",
    "    loss_adv = -torch.mean(out)\n",
    "    \n",
    "    # Equivariance loss\n",
    "    # real --> transform(color / tps) --> gen\n",
    "    images_cj = torch.from_numpy(x_real.cpu().detach().numpy())\n",
    "    for b in range(images_cj.shape[0]):\n",
    "        images_cj[b] = torch.from_numpy(transform(images_cj[b]).numpy()*255.0)\n",
    "    tps.reset_control_points()\n",
    "    images_tps = tps(images_cj)\n",
    "    pred_tps, _ =  nets.generator((images_tps/255.0).to(device), y_org)\n",
    "    pred_tps = interp(pred_tps)\n",
    "    # real --> gen --> transform(tps)\n",
    "    pred_d = x_fake.cpu().detach()\n",
    "    pred_d.requires_grad = False\n",
    "    pred_tps_org = tps(pred_d, padding_mode='zeros')\n",
    "    # Center: first center - second center\n",
    "    centers_tps = center.batch_get_centers(softmax(pred_tps)[:, 1:, :, :])\n",
    "    pred_tps_gen = tps(x_fake.cpu(), padding_mode='zeros')\n",
    "    centers_tps_gen = center.batch_get_centers(softmax(pred_tps_gen.to(device))[:, 1:, :, :])\n",
    "    # KL (first, second) / Center mse (first, second)\n",
    "    loss_eqv = kl(F.log_softmax(pred_tps, dim=1), F.softmax(pred_tps_org.to(device)))\n",
    "    loss_center = F.mse_loss(centers_tps, centers_tps_gen)\n",
    "\n",
    "    # cycle-consistency loss\n",
    "    x_rec, x_tf = nets.generator(x_fake, x_real)\n",
    "    loss_cyc = torch.mean(torch.abs(x_rec - x_real)) + torch.mean(torch.abs(x_att - x_tf))\n",
    "\n",
    "    loss = loss_adv + args.lambda_cyc * loss_cyc + args.lambda_eqv * loss_eqv + args.lambda_eqv * loss_center\n",
    "    return loss, Munch(adv=loss_adv.item(), cyc=loss_cyc.item(), eqv=loss_eqv.item(), center=loss_center.item())\n",
    "\n",
    "def compute_tf_loss(nets, args, x_att, t_att, device='cuda'):\n",
    "    pass\n",
    "\n",
    "def gradient_penalty(nets, real, fake, reg_lambda=10, device='cuda'):\n",
    "    from torch.autograd import grad\n",
    "    batch_size = real.shape[0]\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    merged = (epsilon * real) + ((1 - epsilon) * fake)\n",
    "    # forward\n",
    "    op = nets.discriminator(merged)\n",
    "    \n",
    "    # merted gradient\n",
    "    gradient = grad(outputs=op, inputs=merged, create_graph=True, grad_outputs=torch.ones_like(op), \n",
    "                    retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    # calc penalty\n",
    "    penalty = reg_lambda * ((gradient.norm(p=2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty\n",
    "    \n",
    "\n",
    "def moving_average(model, model_test, beta=0.999):\n",
    "    for param, param_test in zip(model.parameters(), model_test.parameters()):\n",
    "        param_test.data = torch.lerp(param.data, param_test.data, beta)\n",
    "\n",
    "\n",
    "def adv_loss(logits, target):\n",
    "    assert target in [1, 0]\n",
    "    targets = torch.full_like(logits, fill_value=target)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def r1_reg(d_out, x_in):\n",
    "    # zero-centered gradient penalty for real images\n",
    "    batch_size = x_in.size(0)\n",
    "    grad_dout = torch.autograd.grad(\n",
    "        outputs=d_out.sum(), inputs=x_in,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    assert(grad_dout2.size() == x_in.size())\n",
    "    reg = 0.5 * grad_dout2.view(batch_size, -1).sum(1).mean(0)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n",
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MotionDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=True, random_seed=config.seed)\n",
    "test_dataset = FramesDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=False, random_seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRepeater(train_dataset, config.num_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                              num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = Munch(src=train_loader, val=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of generator: 59922063\n",
      "Number of parameters of discriminator: 20851777\n",
      "Initializing generator...\n",
      "Initializing discriminator...\n"
     ]
    }
   ],
   "source": [
    "solver = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Resuming from checkpoint..\n"
     ]
    }
   ],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'), resume=True)\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'))\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'))\n",
    "    logger.set_names(['WGAN-GP Loss', 'R1reg Loss', 'G-latent-adv Loss', 'G-cyclc Loss', 'Equivariance Loss', 'Eqv-center Loss'])\n",
    "    val_logger.set_names(['SSIM measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from logs/tf3/checkpoints/000042_nets.ckpt...\n",
      "Loading checkpoint from logs/tf3/checkpoints/000042_nets_ema.ckpt...\n",
      "Loading checkpoint from logs/tf3/checkpoints/000042_optims.ckpt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep:45, WGP: -1.006726, R1: 9.62, G: 40.559285, Cyc: 0.144082, Eqv: 0.000735, Ct: 0.000087:   4%|▎         | 56/1536 [02:58<1:13:07,  2.96s/it]    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c1f0897ef4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-020af5edb4a0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0;31m# train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_losses_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_d_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_drive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-020af5edb4a0>\u001b[0m in \u001b[0;36mcompute_d_loss\u001b[0;34m(nets, args, x_real, y_org, device)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrift\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_out\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mx_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_gp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-020af5edb4a0>\u001b[0m in \u001b[0;36mgradient_penalty\u001b[0;34m(nets, real, fake, reg_lambda, device)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solver.train(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
