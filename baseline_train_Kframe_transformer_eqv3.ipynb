{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as ospj\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import deque\n",
    "\n",
    "from network.model_tf import build_model\n",
    "from core.checkpoint import CheckpointIO\n",
    "# from dataset.data_loader import InputFetcher\n",
    "from dataset.frame_dataset import FramesDataset, MotionDataset, DatasetRepeater\n",
    "import network.utils as utils\n",
    "import yaml\n",
    "import random\n",
    "from utils import Bar, Logger, AverageMeter, center\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "import pytorch_ssim\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from tps.rand_tps import RandTPS\n",
    "from network.vgg import VGG\n",
    "import imp\n",
    "from network.heatmap import FAN, HighPass\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/train_transformer4.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Munch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0,1,2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.args.lr = float(self.args.lr)\n",
    "        self.args.weight_decay = float(self.args.weight_decay)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.start = 10\n",
    "        self.replay_memory = 10000\n",
    "        self.replay_buffer = deque(maxlen=self.replay_memory)\n",
    "\n",
    "        self.nets, self.nets_ema = build_model(args)\n",
    "        # below setattrs are to make networks be children of Solver, e.g., for self.to(self.device)\n",
    "        for name, module in self.nets.items():\n",
    "            utils.print_network(module, name)\n",
    "            setattr(self, name, module)\n",
    "        for name, module in self.nets_ema.items():\n",
    "            setattr(self, name + '_ema', module)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.optims = Munch()\n",
    "            for net in self.nets.keys():\n",
    "                self.optims[net] = torch.optim.Adam(params=self.nets[net].parameters(), lr=float(args.lr), betas=[args.beta1, args.beta2],\n",
    "                                                   weight_decay=0)\n",
    "\n",
    "            self.ckptios = [\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets.ckpt'), **self.nets),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema),\n",
    "                CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_optims.ckpt'), **self.optims)]\n",
    "        else:\n",
    "            self.ckptios = [CheckpointIO(ospj(args.checkpoint_dir, '{:06d}_nets_ema.ckpt'), **self.nets_ema)]\n",
    "    \n",
    "\n",
    "        self.to(self.device)\n",
    "        for name, network in self.named_children():\n",
    "            # Do not initialize the FAN parameters\n",
    "            if ('ema' not in name) and ('fan' not in name):\n",
    "                print('Initializing %s...' % name)\n",
    "                network.apply(utils.he_init)\n",
    "        \n",
    "        # heatmap\n",
    "        self.fan = FAN(config)\n",
    "        self.hpf = HighPass(config.w_hpf, self.device)\n",
    "        \n",
    "        # eqv\n",
    "        self.eqv_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=config.brightness, contrast=config.contrast, saturation=config.saturation, hue=config.hue),\n",
    "            transforms.ToTensor(),])\n",
    "        self.interp = nn.Upsample(size=(config.img_size, config.img_size), mode='bilinear', align_corners=True)\n",
    "        self.tps = RandTPS(width=config.img_size, height=config.img_size, batch_size=config.batch_size, sigma=config.sigma, \n",
    "                           border_padding=True, random_mirror=True, random_scale=(0.8, 1.1))\n",
    "        self.kl = nn.KLDivLoss().to(self.device)\n",
    "        \n",
    "        # perceptual loss\n",
    "        self.vgg = VGG()\n",
    "        MainModel = imp.load_source(\"MainModel\", args.fname_ir)\n",
    "        weight = torch.load(args.fname_vgg, map_location='cpu')\n",
    "        self.vgg.load_state_dict(weight.state_dict(), strict=False)\n",
    "        self.vgg.eval()\n",
    "        self.vgg.to(self.device)\n",
    "        \n",
    "\n",
    "    def _save_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.save(step)\n",
    "\n",
    "    def _load_checkpoint(self, step):\n",
    "        for ckptio in self.ckptios:\n",
    "            ckptio.load(step)\n",
    "\n",
    "    def _reset_grad(self):\n",
    "        for optim in self.optims.values():\n",
    "            optim.zero_grad()\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, args, epoch, nets, loader):\n",
    "        if not os.path.isdir(args.result_dir):\n",
    "            os.makedirs(args.result_dir)\n",
    "        result_target = os.path.join(args.result_dir, 'tar')\n",
    "        result_gen = os.path.join(args.result_dir,'gen')\n",
    "        if not os.path.isdir(result_target):\n",
    "            os.makedirs(result_target)\n",
    "        if not os.path.isdir(result_gen):\n",
    "            os.makedirs(result_gen)\n",
    "        \n",
    "        bar = tqdm(total=len(loader), leave=False)\n",
    "        ssim_meter, fid_meter = AverageMeter(), AverageMeter()\n",
    "        for iteration, x in enumerate(loader):\n",
    "            try:\n",
    "                test_video = torch.tensor(np.concatenate(x['video'])) # (frame, c, w, h)\n",
    "            except:\n",
    "                continue\n",
    "            num_frame = test_video.shape[0]\n",
    "            k_frame = np.random.choice(num_frame-args.K, size=2, replace=False)\n",
    "            source = test_video[[k_frame[0]]]\n",
    "            target = test_video[[k_frame[1]]]\n",
    "            source_out = nets.transformer(source.to(self.device), target.to(self.device))\n",
    "            source_out = self.heatmap_tf(args, source_out)\n",
    "            source_gen = nets.generator(source.to(self.device), target.to(self.device), source_out.to(self.device))\n",
    "            ssim = float(pytorch_ssim.ssim(source_gen, target.to(self.device)))\n",
    "            ssim_meter.update(ssim, iteration+1)\n",
    "            \n",
    "            # save for FID\n",
    "            gen = source_gen.squeeze().cpu().detach().numpy()\n",
    "            target = target.squeeze().cpu().detach().numpy()\n",
    "            gen = gen.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            target = target.swapaxes(0, 1).swapaxes(1, 2)\n",
    "            gen_img = Image.fromarray((gen*255).astype('uint8'))\n",
    "            tar_img = Image.fromarray((target*255).astype('uint8'))\n",
    "            gen_img.save(result_gen + '/{}.png'.format(iteration+1))\n",
    "            tar_img.save(result_target + '/{}.png'.format(iteration+1))\n",
    "            \n",
    "            bar.set_description(\"Epoch:{:d}, SSIM: {:.8f}\".format(epoch+1, ssim_meter.avg), refresh=True)\n",
    "            bar.update()\n",
    "        bar.close()\n",
    "        val_logger.append([str(ssim_meter.avg)])\n",
    "        return\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def make_animation(self, args, nets, loaders):\n",
    "        if not os.path.isdir(args.sample_dir):\n",
    "            os.makedirs(args.sample_dir)\n",
    "        K = 100\n",
    "        random_list = np.random.choice(len(loaders.val.dataset), replace=False, size=2)\n",
    "        source_image_idx = int(random_list[0])\n",
    "        test_video_idx = int(random_list[1])\n",
    "        train_video_idx = int(np.random.choice(len(loaders.src.dataset), size=1))\n",
    "        # test animation\n",
    "        source_image = loaders.val.dataset[source_image_idx]['video'][0]\n",
    "        test_video = loaders.val.dataset[test_video_idx]['video'] # list [video](3, 256, 256)\n",
    "        train_video = loaders.src.dataset[train_video_idx]['target'] # list [K](3, 256, 256)\n",
    "        test_frame = len(test_video) if len(test_video) < K else K\n",
    "        train_frame = len(train_video)\n",
    "        predict_test, predict_train = [], []\n",
    "        for i in range(test_frame):\n",
    "            out = nets.transformer(source_image.to(self.device).unsqueeze(0), test_video[i].to(self.device).unsqueeze(0))\n",
    "            out = self.heatmap_tf(args, out)\n",
    "            gen = nets.generator(source_image.to(self.device).unsqueeze(0), test_video[i].to(self.device).unsqueeze(0), out.to(self.device))\n",
    "            predict_test.append(gen.cpu().detach().numpy().squeeze().swapaxes(0, 1).swapaxes(1,2))\n",
    "        \n",
    "        for i in range(train_frame):\n",
    "            out = nets.transformer(source_image.to(self.device).unsqueeze(0), train_video[i].to(self.device).unsqueeze(0))\n",
    "            out = self.heatmap_tf(args, out)\n",
    "            gen  = nets.generator(source_image.to(self.device).unsqueeze(0), train_video[i].to(self.device).unsqueeze(0), out.to(self.device))\n",
    "            predict_train.append(gen.cpu().detach().numpy().squeeze().swapaxes(0,1).swapaxes(1,2))\n",
    "        self.predict_test = predict_test\n",
    "        source_image = (source_image*255).numpy().swapaxes(0,1).swapaxes(1,2).astype('uint8')\n",
    "        source_img = Image.fromarray(source_image)\n",
    "        source_img.save(config.sample_dir+ '/source.png')\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_test], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'test_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in test_video], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_gen.mp4'), [(frame*255).astype('uint8') for frame in predict_train], fps=24)\n",
    "        imageio.mimsave(os.path.join(config.sample_dir, 'train_raw.mp4'), [(frame*255).numpy().astype('uint8').swapaxes(0,1).swapaxes(1,2) for frame in train_video], fps=24)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def heatmap_tf(self, args, out):\n",
    "        mask = self.fan.get_heatmap(out)\n",
    "        mask = F.interpolate(mask, size=args.img_size, mode='bilinear')\n",
    "        hpf_mask = self.hpf(mask)\n",
    "        x_out = out + hpf_mask\n",
    "        return x_out\n",
    "    \n",
    "    def train(self, loaders):\n",
    "        args = self.args\n",
    "        nets = self.nets\n",
    "        nets_ema = self.nets_ema\n",
    "        \n",
    "        for name in nets:\n",
    "            nets[name] = DataParallel(nets[name])\n",
    "            nets[name] = nets[name].to(self.device)\n",
    "        optims = self.optims\n",
    "\n",
    "        # resume training if necessary\n",
    "        if args.resume_iter > 0:\n",
    "            self._load_checkpoint(args.resume_iter)\n",
    "\n",
    "        # batch\n",
    "        for epoch in range(args.resume_iter, args.epochs):\n",
    "            bar = tqdm(total=len(loaders.src)*args.K, leave=False)\n",
    "            tf_loss, eqv_loss, center_loss = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            wgan_loss, d_reg_loss = AverageMeter(), AverageMeter()\n",
    "            g_latent_loss, g_cycle_loss, vgg_loss = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            for i, inputs in enumerate(loaders.src):\n",
    "                x_source, y_drive = inputs['source'], inputs['target']\n",
    "                num_frame = len(y_drive)\n",
    "                for f in range(num_frame):\n",
    "                    self.replay_buffer.append((x_source, y_drive[f]))\n",
    "                    \n",
    "                    if len(self.replay_buffer) < self.start:\n",
    "                        continue\n",
    "                    minibatch = random.sample(self.replay_buffer, 1)\n",
    "                    x_source_mb, y_drive_mb = minibatch[0][0], minibatch[0][1]\n",
    "                    \n",
    "                    # train the transformer\n",
    "                    x_out, tf_losses, tf_losses_latent = compute_tf_loss(nets, args, x_source_mb, y_drive_mb,\n",
    "                                                                         transform=self.eqv_transform, tps=self.tps, interp=self.interp, \n",
    "                                                                         kl=self.kl, heatmap=self.heatmap_tf,\n",
    "                                                                         device=self.device)\n",
    "  \n",
    "                    self._reset_grad()\n",
    "                    tf_losses.backward()\n",
    "                    optims.transformer.step()\n",
    "                    \n",
    "                    # train the discriminator\n",
    "                    d_loss, d_losses_latent = compute_d_loss(nets, args, x_source_mb, y_drive_mb, x_out, device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    d_loss.backward()\n",
    "                    optims.discriminator.step()\n",
    "\n",
    "                    # train the generator\n",
    "                    g_loss, g_losses_latent = compute_g_loss(nets, args, x_source_mb, y_drive_mb, x_out, vgg=self.vgg, \n",
    "                                                             fan=self.fan, hpf=self.hpf, device=self.device)\n",
    "                    self._reset_grad()\n",
    "                    g_loss.backward()\n",
    "                    optims.generator.step()\n",
    "                    \n",
    "                    moving_average(nets.generator, nets_ema.generator, beta=0.999)\n",
    "\n",
    "                    wgan_loss.update(float(d_losses_latent.wgangp), x_source.size(0))\n",
    "                    d_reg_loss.update(float(d_losses_latent.reg), x_source.size(0))\n",
    "                    g_latent_loss.update(float(g_losses_latent.adv), x_source.size(0))\n",
    "                    g_cycle_loss.update(float(g_losses_latent.cyc), x_source.size(0))\n",
    "                    vgg_loss.update(float(g_losses_latent.vgg), x_source.size(0))\n",
    "                    tf_loss.update(float(tf_losses_latent.tf), x_source.size(0))\n",
    "                    eqv_loss.update(float(tf_losses_latent.eqv), x_source.size(0))\n",
    "                    center_loss.update(float(tf_losses_latent.center), x_source.size(0))\n",
    "\n",
    "                    bar.set_description(\"Ep:{:d}, WGP: {:.6f}, R1: {:.2f}, G: {:.6f}, Cyc: {:.6f}, Vgg: {:.6f}, TF: {:.6f}, Eqv: {:.6f}, Ct: {:.6f}\".format(\n",
    "                                        epoch+1, wgan_loss.avg, d_reg_loss.avg, \n",
    "                                        g_latent_loss.avg, g_cycle_loss.avg, vgg_loss.avg,\n",
    "                                        tf_loss.avg, eqv_loss.avg, center_loss.avg), refresh=True)\n",
    "                    bar.update()\n",
    "            bar.close()\n",
    "\n",
    "                # save model checkpoints\n",
    "            logger.append([str(wgan_loss.avg)[:8], str(d_reg_loss.avg)[:8], \n",
    "                           str(g_latent_loss.avg)[:8], str(g_cycle_loss.avg)[:8], str(vgg_loss.avg)[:8],\n",
    "                           str(tf_loss.avg)[:8], str(eqv_loss.avg)[:8], str(center_loss.avg)[:8]])\n",
    "            if (epoch+1) % config.save_every == 0:\n",
    "                self._save_checkpoint(step=epoch+1)\n",
    "\n",
    "            # compute SSIM and FID in test_set\n",
    "            if (epoch+1) % config.eval_every == 0:\n",
    "                self.evaluate(args, epoch, nets, loaders.val)\n",
    "                \n",
    "            self.make_animation(args, nets, loaders)\n",
    "        \n",
    "        self.evaluate(args, epoch, nets, loaders.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_d_loss(nets, args, x_real, y_org, x_out, device='cuda'):\n",
    "#     assert (z_trg is None) != (x_ref is None)\n",
    "    # with real images\n",
    "    x_real, y_org, x_out = x_real.to(device), y_org.to(device), x_out.to(device)\n",
    "    x_real.requires_grad = True\n",
    "    real_out = nets.discriminator(x_real)\n",
    "    # R1-reg\n",
    "    loss_reg = r1_reg(real_out, x_real)\n",
    "     # with fake images\n",
    "    with torch.no_grad():\n",
    "        x_fake = nets.generator(x_real, y_org, x_out)\n",
    "    fake_out = nets.discriminator(x_fake)\n",
    "    # WGAN-GP\n",
    "    loss = (torch.mean(fake_out) - torch.mean(real_out) + (args.drift * torch.mean(real_out ** 2)))\n",
    "    x_fake.requires_grad = True\n",
    "    gp = gradient_penalty(nets, x_real, x_fake, args.lambda_gp, device=device)\n",
    "    loss += gp\n",
    "    loss = loss + args.lambda_reg * loss_reg\n",
    "    return loss, Munch(wgangp=loss.item(), reg=loss_reg.item())\n",
    "\n",
    "\n",
    "def compute_g_loss(nets, args, x_real, y_org, x_out, vgg, fan, hpf, device='cuda'):\n",
    "    # adversarial loss: WGAN-GP\n",
    "    x_real, y_org, x_out= x_real.to(device), y_org.to(device), x_out.to(device)\n",
    "    x_fake = nets.generator(x_real, y_org, x_out)\n",
    "    out = nets.discriminator(x_fake)\n",
    "    loss_adv = -torch.mean(out)\n",
    "    \n",
    "    # cycle-consistency loss\n",
    "    with torch.no_grad():\n",
    "        x_fake_out = nets.transformer(x_fake, x_real)\n",
    "        mask_cyc = fan.get_heatmap(x_fake_out)\n",
    "        mask_cyc = F.interpolate(mask_cyc, size=args.img_size, mode='bilinear') * F.interpolate(hpf(fan.get_heatmap(x_fake)), \n",
    "                                                                                                size=args.img_size, mode='bilinear')\n",
    "        hpf_mask = hpf(mask_cyc)\n",
    "        x_fake_out = x_fake_out + hpf_mask\n",
    "\n",
    "    x_fake_out.requires_grad = False\n",
    "    x_rec = nets.generator(x_fake, x_real, x_fake_out)\n",
    "    loss_cyc = torch.mean(torch.abs(x_rec - x_real))\n",
    "    \n",
    "    # perceptual loss\n",
    "    l1_loss = nn.L1Loss()\n",
    "    with torch.no_grad():\n",
    "        vgg_x = vgg(x_real)\n",
    "    with torch.autograd.enable_grad():\n",
    "        vgg_xhat = vgg(x_fake)\n",
    "        \n",
    "    loss_vgg = 0\n",
    "    for x_feat, xhat_feat in zip(vgg_x, vgg_xhat):\n",
    "        loss_vgg += l1_loss(x_feat, xhat_feat)\n",
    "\n",
    "    loss = loss_adv + args.lambda_cyc * loss_cyc + args.lambda_vgg * loss_vgg\n",
    "    return loss, Munch(adv=loss_adv.item(), cyc=loss_cyc.item(), vgg=loss_vgg.item())\n",
    "\n",
    "def compute_tf_loss(nets, args, x_real, y_org, transform, tps, interp, kl, heatmap, device='cuda'):\n",
    "    # TF_loss\n",
    "    l1_loss = nn.L1Loss()\n",
    "    x_real, y_org = x_real.to(device), y_org.to(device)\n",
    "    x_heatmap = heatmap(args, x_real)\n",
    "    y_heatmap = heatmap(args, y_org)\n",
    "    x_out = nets.transformer(x_real, y_org)\n",
    "    x_out = heatmap(args, x_out)\n",
    "    loss_tf = l1_loss(torch.sum(x_out, 1, keepdim=True)/3, torch.sum(y_heatmap, 1, keepdim=True))\n",
    "    \n",
    "    # Equivariance loss\n",
    "    # real --> transform(color / tps) --> gen\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    images_cj = torch.from_numpy(x_real.cpu().detach().numpy())\n",
    "    for b in range(images_cj.shape[0]):\n",
    "        images_cj[b] = torch.from_numpy(transform(images_cj[b]).numpy()*255.0)\n",
    "    tps.reset_control_points()\n",
    "    images_tps = tps(images_cj)\n",
    "    pred_tps =  nets.transformer((images_tps/255.0).to(device), y_org)\n",
    "    pred_tps = interp(pred_tps)\n",
    "    # real --> gen --> transform(tps)\n",
    "    pred_d = x_out.cpu().detach()\n",
    "    pred_d.requires_grad = False\n",
    "    pred_tps_org = tps(pred_d, padding_mode='zeros')\n",
    "    # Center: first center - second center\n",
    "    centers_tps = center.batch_get_centers(softmax(pred_tps)[:, 1:, :, :])\n",
    "    pred_tps_gen = tps(x_out.cpu(), padding_mode='zeros')\n",
    "    centers_tps_gen = center.batch_get_centers(softmax(pred_tps_gen.to(device))[:, 1:, :, :])\n",
    "    # KL (first, second) / Center mse (first, second)\n",
    "    loss_eqv = kl(F.log_softmax(pred_tps, dim=1), F.softmax(pred_tps_org.to(device)))\n",
    "    loss_center = F.mse_loss(centers_tps, centers_tps_gen)\n",
    "    loss = loss_tf * args.lambda_tf + loss_eqv * args.lambda_eqv + loss_center * args.lambda_eqv\n",
    "    return x_out, loss, Munch(tf=loss_tf.item(), eqv=loss_eqv.item(), center=loss_center.item())\n",
    "    \n",
    "\n",
    "def gradient_penalty(nets, real, fake, reg_lambda=10, device='cuda'):\n",
    "    from torch.autograd import grad\n",
    "    batch_size = real.shape[0]\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    merged = (epsilon * real) + ((1 - epsilon) * fake)\n",
    "    # forward\n",
    "    op = nets.discriminator(merged)\n",
    "    \n",
    "    # merted gradient\n",
    "    gradient = grad(outputs=op, inputs=merged, create_graph=True, grad_outputs=torch.ones_like(op), \n",
    "                    retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    # calc penalty\n",
    "    penalty = reg_lambda * ((gradient.norm(p=2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty\n",
    "    \n",
    "\n",
    "def moving_average(model, model_test, beta=0.999):\n",
    "    for param, param_test in zip(model.parameters(), model_test.parameters()):\n",
    "        param_test.data = torch.lerp(param.data, param_test.data, beta)\n",
    "\n",
    "\n",
    "def adv_loss(logits, target):\n",
    "    assert target in [1, 0]\n",
    "    targets = torch.full_like(logits, fill_value=target)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def r1_reg(d_out, x_in):\n",
    "    # zero-centered gradient penalty for real images\n",
    "    batch_size = x_in.size(0)\n",
    "    grad_dout = torch.autograd.grad(\n",
    "        outputs=d_out.sum(), inputs=x_in,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    assert(grad_dout2.size() == x_in.size())\n",
    "    reg = 0.5 * grad_dout2.view(batch_size, -1).sum(1).mean(0)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n",
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MotionDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=True, random_seed=config.seed)\n",
    "test_dataset = FramesDataset(config.root_dir, image_shape=config.frame_shape, id_sampling=True, is_train=False, random_seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRepeater(train_dataset, config.num_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                              num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = Munch(src=train_loader, val=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of generator: 42371715\n",
      "Number of parameters of discriminator: 20851777\n",
      "Number of parameters of transformer: 26263552\n",
      "Initializing generator...\n",
      "Initializing discriminator...\n",
      "Initializing transformer...\n"
     ]
    }
   ],
   "source": [
    "solver = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'), resume=True)\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(config.checkpoint_dir, 'log.txt'))\n",
    "    val_logger = Logger(os.path.join(config.checkpoint_dir, 'val_log.txt'))\n",
    "    logger.set_names(['WGAN-GP Loss', 'R1reg Loss', 'G-latent-adv Loss', 'G-cyclc Loss', 'Perceptual Loss', 'TF L1 Loss', 'Equivariance Loss', 'Eqv-center Loss'])\n",
    "    val_logger.set_names(['SSIM measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint into logs/tf4/checkpoints/000001_nets.ckpt...\n",
      "Saving checkpoint into logs/tf4/checkpoints/000001_nets_ema.ckpt...\n",
      "Saving checkpoint into logs/tf4/checkpoints/000001_optims.ckpt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep:2, WGP: -2.340452, R1: 16.90, G: 8.492082, Cyc: 0.471584, Vgg: 3.689360, TF: 4.055825, Eqv: 0.222417, Ct: 0.000041:  29%|██▊       | 247/864 [18:48<47:29,  4.62s/it]   "
     ]
    }
   ],
   "source": [
    "solver.train(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
